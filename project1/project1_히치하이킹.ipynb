{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project1_히치하이킹.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vfXptJFvIB3X"
      ],
      "authorship_tag": "ABX9TyOpv0aRzMpT/+hfN2DSSMpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwonbuyeon/2021-1_basicCarAI/blob/master/project1/project1_%ED%9E%88%EC%B9%98%ED%95%98%EC%9D%B4%ED%82%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jZ8JayaEEN5"
      },
      "source": [
        "**자율주행 택시를 위한 오프라인 택시 잡기 기능 히치하이킹**\n",
        "\n",
        "(Mediapipe를 활용한 차량 지능 관련 자유 프로젝트)\n",
        "권부연_20203030"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhW7zPneEgJn"
      },
      "source": [
        "이후 자율주행이 보편화된 시대가 되었을때 스마트폰을 통한 자율주행 콜택시, 자율주행 택시를 위한 정류장 등이 생길 수 있다. \n",
        "\n",
        "그리고 스마트폰을 사용하지 못할 때 지금의 택시를 부르듯 특정 행동으로 택시를 잡을 수 있으면 좋을 것이라고 생각했다.그래서 히치하이킹에서 영감을 받아 히치하이킹 동작을 인식할 수 있는 프로그램을 개발하였다.\n",
        "\n",
        "\n",
        "다만, 이것이 가능하기위해선 자율주행차가 지금의 택시가 그러듯 일정 경로를 반복적으로 순회하거나 돌아다녀야 하겠지만, 이는 히치하이킹에서 뿐만 아니라 더 빠르게 콜택시나 정류장 호출에 반응할 수 있는 장점이 있다고 생각한다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVeV5AMPM-2r"
      },
      "source": [
        "사용 오픈소스\n",
        "> holistic\n",
        "https://google.github.io/mediapipe/solutions/holistic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tJj_RCkPwYk"
      },
      "source": [
        "* test용 파일 다운 링크\n",
        "\n",
        "\n",
        "https://github.com/kwonbuyeon/2021-1_basicCarAI/tree/master/project1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UWjjjx6GCUb"
      },
      "source": [
        "-------------\n",
        "\n",
        "mediapipe 연결 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKVrmMNbqfFH",
        "outputId": "d554504d-96fa-4431-ac5d-35191d15d675"
      },
      "source": [
        "pip install mediapipe"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.36.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (20.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (56.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfXptJFvIB3X"
      },
      "source": [
        "# 웹캠으로 바로 캡쳐한 사진 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKJ7-PaHrqVr"
      },
      "source": [
        "\n",
        "선택사항) 혹시 바로 사진을 캡쳐하여 사용하고 싶다면 아래 shell를 실행하고 main에서 사진을 처리하는 코드를 활용한 후 파일이름 대신해 take_photo()를 사용하여야한다.\n",
        "\n",
        "(웹캠 capture 기능) filename대신 take_photo()를 넣으면 바로 Capture한 사진을 사용할 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vLXQoTXwBdR"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG_FTymguTiH"
      },
      "source": [
        "#손 모양 인식 구현부"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KpYWEFsI2vO"
      },
      "source": [
        "gijun(손목)과의 거리 차이(linesize값)를 기준으로 손가락을 펼친 여부 파악(isfold) \n",
        "point1(손가락 세번째마디), point2(손끝)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtqg9hPoRc4r"
      },
      "source": [
        "def linesize(gijun,point):\n",
        "  return (point.x-gijun.x)**2+(point.y-gijun.y)**2\n",
        "\n",
        "def isfold(gijun,point1,point2):\n",
        "  result = True\n",
        "  if linesize(gijun,point1) > linesize(gijun,point2):\n",
        "    result = False\n",
        "  return result"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3lRoMKnJfUJ"
      },
      "source": [
        "찾은 손의 따봉 여부 판단\n",
        "\n",
        "참고)\n",
        "hands\n",
        "https://google.github.io/mediapipe/solutions/hands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJACu9LoDjI"
      },
      "source": [
        "def ishandHich(hand_landmarks):\n",
        "  if hand_landmarks != None:#손이 인식되었는가\n",
        "    if isfold(hand_landmarks.landmark[17],hand_landmarks.landmark[2],hand_landmarks.landmark[4]):#엄지를 추켜세웠는가\n",
        "          isUnfolding= True\n",
        "          for i in range(6,19,4):#엄지외의 손가락을 접었는가\n",
        "            if isfold(hand_landmarks.landmark[0],hand_landmarks.landmark[i],hand_landmarks.landmark[i+2]):\n",
        "              isUnfolding = False\n",
        "              break\n",
        "          if isUnfolding:\n",
        "            return True\n",
        "  return False"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFCeuaWNH7Fq"
      },
      "source": [
        "# 손모양과 손위치로 히치하이킹 여부 추정 구현부\n",
        "\n",
        "주어진 이미지가 히치하이킹하고 있다 판단되면 히치하이킹하는 손을 글자로 표시해줌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKSQuIFKKHal"
      },
      "source": [
        "손을 엄덩이 보다 머리에 가깝게 들고있는지 확인한다. 손을 기준으로 머리가 엉덩이보다 가까이 있다면 true를 리턴한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-7KXwuOsuan"
      },
      "source": [
        "def ishandUp(head, hip, hand):\n",
        "  return isfold(hand,head,hip)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxFB4K4HKZ7N"
      },
      "source": [
        "히치하이킹을 할 정도의 손위치에서 따봉을 하고 있다면 좌측 상단에 hich라는 글자를 표시한 이미지를 리턴한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS9GjBL1mXbU"
      },
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "def hich(image):\n",
        "  mp_drawing = mp.solutions.drawing_utils\n",
        "  mp_holistic = mp.solutions.holistic\n",
        "\n",
        "# For static images:\n",
        "  with mp_holistic.Holistic(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=2) as holistic:\n",
        "\n",
        "    image_height, image_width, _ = image.shape\n",
        "    # Convert the BGR image to RGB before processing.\n",
        "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "    # Draw pose, left and right hands, and face landmarks on the image.\n",
        "    annotated_image = image.copy()\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
        "\n",
        "      #draw hich\n",
        "    if results.pose_landmarks:\n",
        "      pose_landmark=results.pose_landmarks\n",
        "      #right hand\n",
        "      word = \"\"\n",
        "      if ishandUp(pose_landmark.landmark[0],pose_landmark.landmark[24],pose_landmark.landmark[16]):\n",
        "        if ishandHich(results.right_hand_landmarks):\n",
        "          word += \"right hitch \"\n",
        "          #print(\"hitch raght hand!\")\n",
        "      #left hand\n",
        "      if ishandUp(pose_landmark.landmark[0],pose_landmark.landmark[23],pose_landmark.landmark[15]):\n",
        "        if ishandHich(results.left_hand_landmarks):\n",
        "          word += \"left hitch\"\n",
        "          #print(\"hitch left hand!\")\n",
        "      cv2.putText(annotated_image, word, (20, 90), 0, 2, (200,0,0),3)\n",
        "      \n",
        "\n",
        "      #make file\n",
        "      return annotated_image"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ85trTfK7tV"
      },
      "source": [
        "# main 실행부분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1qEPsfHLGSf"
      },
      "source": [
        "선택사항)비디오를 입력한 경우 hich와 자세를 표시한 비디오를 리턴한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rfWnXYZ3aey"
      },
      "source": [
        "def video2segemented_video(video_path):\n",
        "    #load video\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "  \n",
        "    #setting video options (fps, width, height는 기존 영상과 같게 설정하였습니다.)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "    height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "    segVideo = cv2.VideoWriter(\"/content/checked Video.avi\",fourcc,fps,(int(width), int(height)))\n",
        "\n",
        "    print(\"start\")\n",
        "    #프레임 이미지 수정 및 저장\n",
        "    while True :\n",
        "        ret, frame = video.read()#프레임 이미지 가져오기 (ret : frame이 정산적으로 가져와졌는지, frame : 이미지)\n",
        "        if not(ret):\n",
        "            break\n",
        "        image = hich(frame)#이미지에 차선 그리기\n",
        "        #cv2_imshow(image)\n",
        "        segVideo.write(image)#저장할 동영상으로 이미지넣기\n",
        "\n",
        "    video.release()\n",
        "    segVideo.release()\n",
        "    print(\"Successfully Done! check the file 'checked Video.avi' in your folder\")"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UrHXX_aLV0I"
      },
      "source": [
        "main\n",
        "\n",
        "\n",
        "*   이미지 입력 시\n",
        "\n",
        "\n",
        "> cv2.imwrite('출력 파일 경로', hich(cv2.imread(\"입력 파일경로\")))\n",
        "\n",
        "웹캠 캡쳐이미지 사용 시 \"입력 파일경로\"위치에 take_photo() 사용\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   동영상 입력 시\n",
        "\n",
        "\n",
        "> video_path = \"입력 파일경로\" \n",
        "video2segemented_video(video_path)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ZEEIxi2YCg",
        "outputId": "50c467ec-21f9-44b7-9633-9b64e300c5c1"
      },
      "source": [
        "#cv2.imwrite( '/content/checked picture.png',hich(cv2.imread(\"/content/project1_testpicture.jpg\")))\n",
        "video_path = \"/content/project1_testvideo.mp4\" # input your video path\n",
        "video2segemented_video(video_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}